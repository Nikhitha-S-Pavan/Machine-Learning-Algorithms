{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "email_spam_detector.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOsyNypFI4ZiNpv0a0ePaLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhitha-S-Pavan/Machine-Learning-Algorithms/blob/main/email_spam_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koQ7VGilPvNh"
      },
      "source": [
        "\n",
        "#import all the needed libraries\n",
        "import mailbox\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import pandas\n",
        "import sklearn\n",
        "#import cPickle\n",
        "import numpy as np\n",
        "\n",
        "#function to get email text from email body\n",
        "def getmailtext(message): #getting plain text 'email body'\n",
        "    body = None\n",
        "    #check if mbox email message has multiple parts\n",
        "    if message.is_multipart():\n",
        "        for part in message.walk():\n",
        "            if part.is_multipart():\n",
        "                for subpart in part.walk():\n",
        "                    if subpart.get_content_type() == 'text/plain':\n",
        "                        \n",
        "                        body = subpart.get_payload(decode=True)\n",
        "            elif part.get_content_type() == 'text/plain':\n",
        "                body = part.get_payload(decode=True)\n",
        "    #if message only has a single part            \n",
        "    elif message.get_content_type() == 'text/plain':\n",
        "        body = message.get_payload(decode=True)\n",
        "    #return mail text which concatenates both mail subject and body\n",
        "    mailtext=str(message['subject'])+\" \"+str(body)\n",
        "    print(mailtext)\n",
        "    return mailtext\n",
        "\n",
        "\n",
        "#read spam mbox email file\n",
        "mbox = mailbox.mbox('/content/Starred.mbox')\n",
        "smbox = mailbox.mbox('/content/Spam.mbox')\n",
        "\n",
        "star = []\n",
        "count =0\n",
        "#create list which contains mail text for each spam email message\n",
        "for message in mbox:    \n",
        "    star.append(getmailtext(message))\n",
        "    if count>601:\n",
        "        break\n",
        "    count+=1\n",
        "    #break\n",
        "count =0\n",
        "spam = []\n",
        "#create list which contains mail text for each spam email message\n",
        "for message in smbox:    \n",
        "    spam.append(getmailtext(message))\n",
        "    if count>601:\n",
        "        break\n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5YVArwTsBs"
      },
      "source": [
        "\n",
        "#create 2 dataframes for ham spam mails which contain the following info-\n",
        "#Mail text, mail length, mail is ham/spam label\n",
        "import pandas as pd\n",
        "spam_df = pd.DataFrame(spam, columns=[\"message\"])\n",
        "spam_df[\"label\"] = \"spam\"\n",
        "\n",
        "spam_df['length'] = spam_df['message'].map(lambda text: len(text))\n",
        "print(spam_df.head())\n",
        "\n",
        "ham_df = pd.DataFrame(star, columns=[\"message\"])\n",
        "ham_df[\"label\"] = \"ham\"\n",
        "\n",
        "ham_df['length'] = ham_df['message'].map(lambda text: len(text))\n",
        "print(ham_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK3dSTSHTsFG"
      },
      "source": [
        "\n",
        "#merge and shuffle dataframes for ham/spam mails\n",
        "mail_df = pd.concat([spam_df,ham_df])\n",
        "from sklearn.utils import shuffle\n",
        "mail_df = shuffle(mail_df)\n",
        "len(mail_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0YrWOB1TsIa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "mail_train, mail_test, y_train, y_test = train_test_split(mail_df['message'],mail_df['label'],test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtOK_iVNUP7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp6sbDEjUP-F"
      },
      "source": [
        "#for each word in the email text, get the base form of the word and return the list of base words\n",
        "def split_into_lemmas(message):\n",
        "    message = message.lower()\n",
        "    words = TextBlob(message).words\n",
        "    # for each word, take its \"base form\" = lemma\n",
        "    print([word.lemma for word in words])\n",
        "    return [word.lemma for word in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4l_tnsnUQCu"
      },
      "source": [
        "#function to apply the count vectorizer(BOW) and TF-IDF transforms to a set of input features\n",
        "def features_transform(mail):\n",
        "    #get the bag of words for the mail text\n",
        "    bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(mail_train)\n",
        "    print(bow_transformer)\n",
        "    #print(len(bow_transformer.vocabulary_))\n",
        "    messages_bow = bow_transformer.transform(mail)\n",
        "    #print sparsity value\n",
        "    print('sparse matrix shape:', messages_bow.shape)\n",
        "    print('number of non-zeros:', messages_bow.nnz) \n",
        "    print('sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1])))\n",
        "    #apply the TF-IDF transform to the output of BOW\n",
        "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
        "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
        "    \n",
        "    #return result of transforms\n",
        "    return messages_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSwUqZ-2XKss"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhq364yVUQFZ"
      },
      "source": [
        "#transform training set features into a set of useful features to build models\n",
        "train_features=features_transform(mail_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjHkt_6bTsLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}